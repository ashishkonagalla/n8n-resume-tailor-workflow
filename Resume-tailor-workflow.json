{
  "name": "Job Workflow",
  "nodes": [
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyHour"
            }
          ]
        },
        "documentId": {
          "__rl": true,
          "value": "1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE",
          "mode": "list",
          "cachedResultName": "test-joblist",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": "gid=0",
          "mode": "list",
          "cachedResultName": "Jobs",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit#gid=0"
        },
        "event": "rowAdded",
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheetsTrigger",
      "typeVersion": 1,
      "position": [
        -2224,
        224
      ],
      "id": "7053d9f7-05a1-4914-94b5-d43509a4c75b",
      "name": "Google Sheets Trigger",
      "credentials": {
        "googleSheetsTriggerOAuth2Api": {
          "id": "sOkGPE6XlR4t4Xk2",
          "name": "Google Sheets Trigger account 2"
        }
      }
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.category }}",
                    "rightValue": "LinkedIn",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "9d701a48-856e-4f82-9ffc-2eccd3a09e1d"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Linkedin"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "ccc292bf-edf9-4373-939f-1804bc679e6e",
                    "leftValue": "={{ $json.category }}",
                    "rightValue": "Indeed",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "Indeed"
            }
          ]
        },
        "options": {
          "fallbackOutput": "extra"
        }
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.3,
      "position": [
        -272,
        0
      ],
      "id": "5a4a37d5-f443-45dd-85d5-472b0991971c",
      "name": "Switch"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "const url = $json[\"Job Links\"];\n\nif (url.includes(\"linkedin.com\")) {\n  return { json: { link: url, category: \"LinkedIn\" } };\n} else if (url.includes(\"indeed.com\")) {\n  return { json: { link: url, category: \"Indeed\" } };\n} else {\n  return { json: { link: url, category: \"Other\" } };\n}\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -496,
        16
      ],
      "id": "4be2e66e-0922-4429-be11-5fe97be32131",
      "name": "Code in JavaScript1"
    },
    {
      "parameters": {
        "jsCode": "return items.map(item => {\n  return { json: { link: item.json.link } };\n});\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        128,
        48
      ],
      "id": "9746bb5c-38ec-4dd5-955e-6bb1f89b439a",
      "name": "Code in JavaScript"
    },
    {
      "parameters": {
        "operation": "scrape",
        "url": "={{ $json.link }}",
        "scrapeOptions": {
          "options": {
            "formats": {
              "format": [
                {}
              ]
            },
            "headers": {},
            "waitFor": 10000,
            "actions": {
              "items": [
                {
                  "milliseconds": 3000
                }
              ]
            },
            "storeInCache": false
          }
        },
        "requestOptions": {}
      },
      "type": "@mendable/n8n-nodes-firecrawl.firecrawl",
      "typeVersion": 1,
      "position": [
        624,
        176
      ],
      "id": "a03b1a5b-80ec-467f-aab6-96e8fb39b0bf",
      "name": "Scrape a url and get its content",
      "retryOnFail": true,
      "waitBetweenTries": 5000,
      "credentials": {
        "firecrawlApi": {
          "id": "fDIehr4MXT7RwJzZ",
          "name": "Firecrawl account 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-2.5-flash",
          "mode": "list",
          "cachedResultName": "models/gemini-2.5-flash"
        },
        "messages": {
          "values": [
            {
              "content": "=Extract all the relevant job info from the markdown which will be used to tailor the resume.  {{ $json.data.markdown }} Give me two variables in output, one is the source url as is:{{ $json.data.metadata.sourceURL }} and other the modified job info"
            }
          ]
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1296,
        16
      ],
      "id": "428a474d-4699-4161-9b46-e4fafb620473",
      "name": "Message a model",
      "retryOnFail": true,
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE",
          "mode": "list",
          "cachedResultName": "test-joblist",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": 1666930062,
          "mode": "list",
          "cachedResultName": "job-content",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit#gid=1666930062"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "Summarized Content": "={{ $json.content.parts[0].text }}"
          },
          "matchingColumns": [
            "Summarized Content"
          ],
          "schema": [
            {
              "id": "Summarized Content",
              "displayName": "Summarized Content",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.7,
      "position": [
        1936,
        16
      ],
      "id": "11e1e683-dfb4-4103-93a2-e275b301377e",
      "name": "Append row in sheet",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "UpzjIFdaCBQqTUWW",
          "name": "Google Sheets account 2"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "cd7e0632-e03d-46b2-8943-bc1cd9658566",
              "name": "Summary section",
              "value": "Data Engineer and Applied AI Engineer with hands-on experience designing scalable data and AI systems across cloud platforms (AWS, Azure). Skilled in building ETL/ELT pipelines, real-time data workflows, and production-grade ML pipelines using Python, PySpark, Airflow, and FastAPI. Proficient in developing and deploying NLP and LLM models using PyTorch, Hugging Face, and LangChain for document intelligence and automation use cases. Experienced in RAG architectures, vector databases (FAISS, Pinecone), and GenAI integrations to enhance context-aware applications. Strong background in data modeling, performance tuning, and pipeline orchestration for analytics and AI workloads. Adept at translating raw data into deployable intelligence that improves decision-making and operational efficiency. Passionate about bridging the gap between data engineering and applied AI to deliver end-to-end, intelligent data solutions.",
              "type": "string"
            },
            {
              "id": "08768873-96b3-4457-b6a6-36ec305602e8",
              "name": "Experience section",
              "value": "Applied AI Engineer | Jun 2025 – Present | UMBC Research Lab, Baltimore, MD\n• Designed and fine-tuned NLP and LLM models using Python, PyTorch, and Hugging Face to automate text classification and information extraction tasks.\n• Built end-to-end ML pipelines — data preprocessing, model training, evaluation, and deployment — using FastAPI, Docker, and cloud platforms (AWS/Azure).\n• Developed RAG (Retrieval-Augmented Generation) workflows integrating vector databases like FAISS and Pinecone for context-aware Q&A systems.\n• Collaborated with data engineers to optimize data ingestion and feature pipelines, improving model accuracy and scalability.\n• Applied prompt engineering and API integration to embed AI capabilities into internal applications, enhancing automation and user experience.\n\n\n\nUMBC – Residential Life Baltimore, MD Data Engineer (ETL & Analytics) Jul 2023 – Jun 2025 \n• The GAA will work to foster a culture of assessment/evaluation within Residential Life.\nResponsibilities include, but may not be limited to:\n• With departmental Student Affairs Assessment and Research Committee team, develop, write and\nimplement the annual Residential Life Assessment plan\n• Coordinate annual benchmarking assessments (including Skyfactor)\n• Plan, develop and implement qualitative and quantitative assessments such as surveys and/or focus\ngroups\n• Quantitative and qualitative analysis and reporting of results of various assessments\n• Communicate results of assessment projects to residents, staff and the department through emails,\nassessment webpage, and professional development opportunities including RL Lunch & Learns, and\ndepartmental, divisional and University-wide presentations\n• Develop presentations and executive summaries of results, including presenting assessment results at\nannual department retreats and conferences\n• Manage the appropriate storage of departmental data\n• Working with managers of various units in Residential Life, evaluate existing assessment tools and\ndevelop new and enhanced tools.\n• Serve as a departmental representative on the Student Affairs Assessment and Research Committee\n(SAARC) and report committee updates to department\n• Prepare posters and/or presentations for divisional data sharing and professional development events\nincluding New Staff Orientation and Assessment 360\n• Develop professional and paraprofessional staff development sessions as requested\n• Participate with Residential Life and/or Divisional committees as schedule allows\n• Consult with staff at all levels on data tools, and assessment results\n• Attend professional development sessions when opportunities arise\n• Other duties as assigned in helping foster the goals of the Residential Life office\n\n\nIndex Analytics LLC Windsor Mill, MD Software Development Intern – AI/ML (Healthcare Data) Jun 2024 – Sep 2024 \n• Analyzed over a million qualitative patient feedback entries from Centers for Medicare and Medicaid Services (CMS)\ndata, improving nursing home experience evaluations by categorizing feedback into 6 severity levels with advanced\nNLP techniques, resulting in more targeted quality improvement initiatives.\n• Improved classification accuracy by 10% by leveraging AWS SageMaker’s built-in Sentence Pair Classification\nand Named Entity Recognition models, while also evaluating and optimizing multiple BERT models from the AWS\nMarketplace to improve task performance.\n• Explored advanced Generative AI tools, AWS foundational models in Amazon Bedrock, and educated senior\ncompany members—who had limited exposure to trending AI concepts—on key Machine Learning topics like Large\nLanguage Models (LLMs) and Neural Networks through targeted presentations and interactive demos.\n\n\nRemote Tiger Inc. Greenbelt, MD SAS Data Analyst (ETL & Automation) Sep 2022 – Jun 2023 \n• Collaborated with business users and SMEs to understand high level business requirements and specifications.\n• Utilized SAS tools to perform statistical analysis and modeling on the data, including regression and time series analysis.\n• Extracted, transformed, and loaded ETL datasets with basic modeling variables for each segment type using Proc Import,\ndata steps and SQL queries, imported from Oracle database into SAS files.\n• Performed data cleaning by analyzing and eliminating duplicate and inaccurate data using Proc Freq, Proc Comp, Proc\nUnivariate, and various macros in SAS.\n• Developed the project using Git version control and involved in complete lifecycle of software development using Agile.",
              "type": "string"
            },
            {
              "id": "9c1b7e30-a3a9-4436-b7f6-832f252c5d64",
              "name": "Skills section",
              "value": "• Programming & Scripting: Python, Java, R, SAS, SQL (PostgreSQL, MySQL, T-SQL), Scala, Bash\n\n• AI / Machine Learning: PyTorch, TensorFlow, Scikit-learn, Hugging Face Transformers, LangChain, OpenAI API, Vertex AI, Azure ML, Amazon SageMaker, spaCy, NLTK, MLflow, Weights & Biases\n\n• Data Engineering: ETL/ELT pipeline design, Data pipeline orchestration (Apache Airflow, dbt), Apache Spark (PySpark, Spark SQL), Kafka, Dataflow, Pub/Sub\n\n• Generative AI & NLP: LLM fine-tuning, Retrieval-Augmented Generation (RAG), Prompt engineering, Vector databases (FAISS, Pinecone, Chroma), Text summarization & classification, Document Q&A systems\n\n• Cloud Platforms: Google Cloud Platform (BigQuery, Dataflow, Pub/Sub, Cloud Storage), AWS (Glue, Redshift, Lambda, EMR, Bedrock), Azure (Data Factory, Databricks, Synapse, Cognitive Services)\n\n• Databases & Data Warehousing: BigQuery, Oracle, Teradata, DB2, Snowflake, Redshift, Synapse · Data modeling (Star/Snowflake schema) · Query optimization\n\n• Data Quality & Governance: Schema validation, Data profiling, Unit testing, Data quality frameworks\n\n• Visualization & BI: Power BI, Tableau, Looker, QuickSight\n\n• DevOps & Deployment: Docker, FastAPI, REST APIs, CI/CD (GitHub Actions, Azure DevOps), Streamlit, Flask\n\n• Certifications: AWS Machine Learning Engineer – Associate · Microsoft Power BI Data Analyst (PL-300) · Certified Java SE 11 Developer",
              "type": "string"
            },
            {
              "id": "730550be-84a1-4807-941a-5d6aeade1687",
              "name": "Projects Section",
              "value": "Project: HousePriceFlow – Automated ML Pipeline for Housing Price Prediction\n\nTech Stack: Python, scikit-learn, MLflow, Airflow, FastAPI, Docker, AWS (or GCP/Azure), Pandas, NumPy\n\nResume Points:\nDeveloped an end-to-end ML pipeline for housing price prediction, automating data ingestion, preprocessing, model training, and deployment using Airflow.\nImplemented MLflow for experiment tracking and model versioning, logging hyperparameters, RMSE scores, and model artifacts across multiple runs.\nContainerized the FastAPI inference service with Docker and deployed it on AWS Cloud Run, enabling real-time predictions through RESTful APIs.\nOrchestrated periodic retraining workflows with Airflow DAGs, integrating model evaluation logic to promote the best model to production.\nOptimized model performance by tuning features and algorithms (RandomForest, XGBoost), achieving a 15% reduction in RMSE on validation data.\n\n\nProject: LegalMind AI – Generative AI & Applied NLP Assistant\n\nTech Stack: Python, LangChain, OpenAI API, FAISS, Streamlit, FastAPI, Hugging Face Transformers, Docker\n\nResume Points:\nBuilt an LLM-powered legal document assistant enabling intelligent search and Q&A over uploaded contracts using RAG (Retrieval-Augmented Generation).\nEngineered an embedding-based semantic retrieval system with FAISS and OpenAI embeddings, improving context relevance and response precision by 20%.\nIntegrated LangChain to chain retrieval and generation steps, managing prompt templates and conversation memory for contextual query handling.\nDeployed the model via FastAPI backend and Streamlit UI, containerized with Docker and hosted on Railway, enabling interactive legal document chat.\nEnhanced user transparency by displaying source-aware LLM outputs and token usage metrics, demonstrating applied LLMOps and prompt engineering skills.\n\n\nLinear Chain Conditional Random Field (NLP-Transformers-PyTorch)\n• Programmed a Part of Speech (POS) tagging model using Conditional Random Fields (CRF) with linear programming\nfor sequence labeling, achieving 95% accuracy on validation data.\n• Optimized model performance through nonlinear optimization techniques, improving prediction accuracy by 10%.\n• Implemented scalable NLP workflows with Transformers and PyTorch to efficiently process 10,000+ tokens.\n\n\n\nCloud Data Integration Framework (ADF · Databricks · SQL · Azure DevOps)\n• Designed modular ADF pipelines to orchestrate ingestion from APIs, SQL Server, and Blob storage.\n• Integrated Databricks notebooks for PySpark-based joins, transformations, and type-safe validation.\n• Automated CI/CD deployment using Azure DevOps, reducing release time by 50%.\n\n\nSmart Home Energy Optimization - Artificial Intelligence\n● Created an intelligent system combining anomaly detection and predictive modeling to enhance energy efficiency in smart\nhomes by detecting unusual patterns in usage and make predictions on future usage.\n● Followed development lifecycle by going through steps: data collection, data preprocessing, feature engineering, model\nbuilding, model evaluation, optimization, testing, and deployment.\n● Evaluated the trained model using confusion matrix and classification report to assess predictions of usage along with error\nmetrics like MAE (Mean Absolute Error), MSE (Mean Square Error), RMSE (Root Mean Square Error).\n\n\n\nMatrix Completion Problem (Movie Recommendations-Machine Learning) Sep 2024 - Nov 2024\n• Constructed a hybrid collaborative filtering model with matrix factorization to improve recommendation accuracy on\n1M+ MovieLens ratings.\n• Adopted optimization techniques such as Singular Value Decomposition (SVD) and Nuclear Norm Minimization\n(NNM) to achieve 10% faster convergence on sparse data.\n• Validated robust model performance using k-fold cross-validation with RMSE ranging from 0.9 to 1.2.\n\n\nAzure ETL Pipeline (ETL-Databricks-PowerBI-Azure) Jan 2025 - Feb 2025\n• Migrated on-premises SQL to Azure cloud using ADF and ADLS, reducing manual ETL by 40%.\n• Engineered medallion architecture with PySpark in Databricks, improving query performance 3x.\n• Delivered automated data pipeline using Synapse Analytics and Power BI, delivering real-time insights for 5+ KPIs.\n\n\nTech News Intelligence Hub (Kafka-PySpark-Snowflake-Streamlit) Mar 2025 - Apr 2025\n• Built a real-time Kafka–PySpark–Snowflake pipeline to fetch, process, store tech news from APIs with <5s latency.\n• Used PySpark watermarking and checkpointing to ensure exactly-once delivery and cut Snowflake duplicates by 95%.\n• Developed a Streamlit dashboard to visualize real-time Kafka-Snowflake data, showing top companies, trending\ntopics, and hourly news volume with <5s end-to-end latency.\n\n\n\n\n",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        624,
        480
      ],
      "id": "daf71bd8-d6c9-4d76-944c-d1efd04241ed",
      "name": "Edit Fields",
      "executeOnce": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "d81ee892-1d0c-4d7b-8ca6-23a59b095101",
              "name": "Education Section",
              "value": "\\section*{EDUCATION} \\hrule \\vspace{0.1cm} \\noindent\\textbf{\\textsc{University of Maryland, Baltimore County (UMBC)}} \\hfill \\textit{Baltimore, MD}\\\\ \\noindent\\textit{Master of Science, Computer Science (GPA: 3.70/4.00)}\\hfill\\textit{Aug 2023 – May 2025}\\\\ \\noindent\\textit{Bachelor of Science, Computer Science (GPA: 3.41/4.00)}\\hfill\\textit{Aug 2018 – May 2022}\\\\ \\noindent\\textbf{\\small Coursework}: {\\small \\textit{Data Science, Database Management, Algorithms, Machine Learning, Artificial Intelligence, Statistical Analysis}}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        624,
        768
      ],
      "id": "e8c7ec67-8c5d-4bca-a13f-319c5f46aa4a",
      "name": "Edit Fields1",
      "executeOnce": false
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Add a new field called 'myNewField' to the JSON of the item\n$input.item.json.myNewField = 1;\n\nreturn $input.item;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -720,
        16
      ],
      "id": "fe5e9bb2-1a5a-42d1-8ccb-494d774bb324",
      "name": "Code in JavaScript2"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        2208,
        384
      ],
      "id": "1461ab3c-dcd8-4590-b6e5-d2a044f63f5e",
      "name": "Merge",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Role\nYou are a resume optimization AI assistant. Your goal is to transform base experience descriptions into tailored, concise, and quantifiable resume points that align strongly with a given **Job Description (JD)**.\n\n---\n\n## Objective\nYou will read a candidate's **base experience section** and then tailor it for a specific job role, following strict formatting, content, and storytelling instructions.\n\n---\n\n## 📥 Inputs\n\n### 🧾 Job Description\n{{ $json['Summarized Content'] }}\n\n---\n\n### 📄 Base Experience Section\n{{ $json['Experience section'] }}\n\n---\n\n## ✅ Instructions\n\nYou must tailor each job entry in the experience section by following these rules strictly:\n\n### 1. Selection & Relevance\n- Choose the **top 5 points** from each experience that best align with the JD.\n- From those 5, **distill it into 3–4 final bullet points per experience**.\n\n\n### 2. Tailoring Rules\n\n- Apply the following tailoring percentages by role (most recent to oldest):\n\n- **Most Recent Role (1st)** → Tailor up to **80%**\n- **Second Role (2nd)** → Tailor up to **70%**\n- **Third Role (3rd)** → Tailor up to **60%**\n- **Fourth Role (4th)** → Tailor up to **50%**\n\nTailoring percentage = how much of the bullet point wording and framing is customized to the JD. The rest must be preserved from the original base content.\n\n\n### 3. Format & Language\n- Each point must tell a story using an **XYZ format**:\n  - **Accomplished X**, as measured by **Y**, by doing **Z**\n  -  Example: *Improved model accuracy by 15% by optimizing feature selection in a fraud detection pipeline*\n- Each point must:\n  - Start with a **strong, varied action verb**\n  - Be **between 100–120 characters**\n  - Include **measurable outcomes** unless **highly** irrelevant\n  - Use **keywords from the JD** naturally\n\n\n### 4. Style & Structure\n- Use **no more than 4 bullet points per experience**\n- Do **not reuse the same action verb** more than **once across all experiences**. - **This point is very very important**\n- Ensure each bullet focuses on a **specific achievement or contribution**\n- **Avoid filler words** — every word should add value\n\n\n### 5. Storytelling\n- The **final bullet points from each experience** should form a **clear narrative** that highlights the progression, value, and impact of your contributions.\n\n---\n\n##  Output Format\n\nThe final output must follow this exact structure:\n\n[Job Title] | [Dates] | [Company/Org Name], [Location]\n- Bullet point 1 (100–120 characters)\n- Bullet point 2 (100–120 characters)\n- Bullet point 3 (100–120 characters)\n- Bullet point 4 (optional, 100–120 characters)\n\n---\n\n## Example Output (Style Only – Not Content)\n\n\nMachine Learning Intern | Jan 2023 – May 2023 | ABC Labs, New York, NY\nDeveloped XGBoost model to predict demand spikes, improving forecast accuracy by 18%\nAutomated 3 ETL pipelines using Airflow and PySpark, reducing data latency by 40%\nPresented LLM usage findings to 12+ stakeholders, boosting NLP adoption across 2 teams\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3232,
        880
      ],
      "id": "135bac3d-f5ac-4320-bbe4-0247ad065e7a",
      "name": "Basic LLM Chain1",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3392,
        992
      ],
      "id": "7148ae33-0236-48c5-abb6-02956f3e37a7",
      "name": "Google Gemini Chat Model1",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Experience section modification\n",
        "height": 576,
        "width": 816
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2784,
        800
      ],
      "id": "f6e3d0ff-c06c-4400-b37b-682abb290547",
      "name": "Sticky Note1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [
        2336,
        384
      ],
      "id": "3eff784d-d82a-4d4d-84aa-63094743860f",
      "name": "No Operation, do nothing"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "5234e3aa-f159-478b-a78b-664ddd6e650d",
              "leftValue": "={{ $json.success }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1072,
        32
      ],
      "id": "f2f63f20-6c8e-4cdf-8654-055cacc33a72",
      "name": "If"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Role\nYou are a resume optimization AI assistant. Your goal is to transform base experience descriptions into tailored, concise, and quantifiable resume points that align strongly with a given **Job Description (JD)**.\n\n---\n\n## Objective\nYou will read a candidate's **base experience section** and then tailor it for a specific job role, following strict formatting, content, and storytelling instructions.\n\n---\n\n## 📥 Inputs\n\n### 🧾 Job Description\n{{ $json['Summarized Content'] }}\n\n---\n\n### 📄 Base Experience Section\n{{ $json['Experience section'] }}\n\n---\n\n## ✅ Instructions\n\nYou must tailor each job entry in the experience section by following these rules strictly:\n\n### 1. Selection & Relevance\n- Choose the **top 5 points** from each experience that best align with the JD.\n- From those 5, **distill it into 3–4 final bullet points per experience**.\n\n\n### 2. Tailoring Rules\n\n- Apply the following tailoring percentages by role (most recent to oldest):\n\n- **Most Recent Role (1st)** → Tailor up to **80%**\n- **Second Role (2nd)** → Tailor up to **70%**\n- **Third Role (3rd)** → Tailor up to **60%**\n- **Fourth Role (4th)** → Tailor up to **50%**\n\nTailoring percentage = how much of the bullet point wording and framing is customized to the JD. The rest must be preserved from the original base content.\n\n\n### 3. Format & Language\n- Each point must tell a story using an **XYZ format**:\n  - **Accomplished X**, as measured by **Y**, by doing **Z**\n  -  Example: *Improved model accuracy by 15% by optimizing feature selection in a fraud detection pipeline*\n- Each point must:\n  - Start with a **strong, varied action verb**\n  - Be **between 100–120 characters**\n  - Include **measurable outcomes** unless **highly** irrelevant\n  - Use **keywords from the JD** naturally\n\n\n### 4. Style & Structure\n- Use **no more than 4 bullet points per experience**\n- Do **not reuse the same action verb** more than **once across all experiences** - **very very important point. Follow this at any cost**\n- Ensure each bullet focuses on a **specific achievement or contribution**\n- **Avoid filler words** — every word should add value\n\n\n### 5. Storytelling\n- The **final bullet points from each experience** should form a **clear narrative** that highlights the progression, value, and impact of your contributions.\n\n---\n\n##  Output Format\n\nThe final output must follow this exact structure:\n\n[Job Title] | [Dates] | [Company/Org Name], [Location]\n- Bullet point 1 (100–120 characters)\n- Bullet point 2 (100–120 characters)\n- Bullet point 3 (100–120 characters)\n- Bullet point 4 (optional, 100–120 characters)\n\n---\n\n## Example Output (Style Only – Not Content)\n\n\nMachine Learning Intern | Jan 2023 – May 2023 | ABC Labs, New York, NY\nDeveloped XGBoost model to predict demand spikes, improving forecast accuracy by 18%\nAutomated 3 ETL pipelines using Airflow and PySpark, reducing data latency by 40%\nPresented LLM usage findings to 12+ stakeholders, boosting NLP adoption across 2 teams\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3232,
        1152
      ],
      "id": "a43595b4-c396-429c-a59b-3cc976495dd6",
      "name": "Basic LLM Chain3",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=##  Role\nYou are an expert AI assistant for resume optimization, specializing in tailoring skill sections based on a candidate’s master skill bank and the target job description (JD).\n\n---\n\n##  Objective\nGiven:\n1. A comprehensive **base skill bank** (provided below)\n2. A specific **Job Description (JD)**\n\nYour task is to generate a **custom skills section** for the resume that best aligns with the job description.\n\n---\n\n##  Instructions\n\n1. Read the job description thoroughly.\n2. From the provided skill bank, select **at least 80% of the skills** that are **most relevant** to the job role.\n3. Group the selected skills into **5–7 subheadings**, depending on what fits the JD best.\n4. **Each subheading is either a maximum of one word or two words**. Do not exceed that at any circumstance.\n5. **Limit each subheading to a maximum of 6 skills.** Do not exceed this under any condition.\n6. Choose **clear, job-appropriate subheadings** that align with the focus areas of the role (e.g., \"Cloud Platforms\", \"Data Engineering\", etc.).\n7. Use only skills from the skill bank below — **do not invent new ones**.\n8. Include the following **certification section exactly as shown** at the end\n9. The final formatting should strictly follow the output format: all skills in-line, comma-separated, and limited in length.\n\n\n---\n\n##  Input: Job Description\n{{ $json['Summarized Content'] }}\n\n\n---\n\n##  Master Skill Bank\n\n### Programming & Scripting  \nPython, SQL (T-SQL, PL/SQL), Java, Scala, R, Shell Scripting (Bash, PowerShell), JSON, YAML, API Development (REST/gRPC), OOP, Modular Programming, Testing (pytest, unittest)\n\n### Cloud Platforms  \n**Microsoft Azure**: Data Factory, Databricks, Synapse Analytics, Azure Machine Learning, Cognitive Services  \n**AWS**: S3, Glue, Lambda, Redshift, ECS/EKS, SageMaker, Bedrock, Step Functions, EMR  \n**GCP**: BigQuery, Dataflow, Pub/Sub, Vertex AI, AI Platform  \n**Cross-Cloud**: Terraform, CloudFormation, Infrastructure-as-Code (IaC)\n\n### Data Processing, Pipelines & Big Data Frameworks  \nApache Spark (PySpark, Spark SQL), Apache Kafka, Delta Lake, Hadoop (HDFS, MapReduce), Presto, Dask, Lakehouse & Medallion Architecture, Batch & Streaming Data Pipelines, Dataflow, Pub/Sub, Data Lineage & Metadata Management\n\n### ETL / ELT & Workflow Orchestration  \nApache Airflow, dbt, Azure Data Factory, AWS Glue, Apache NiFi, Informatica, Prefect, Kubeflow Pipelines, CI/CD-based pipeline automation, Parameterized DAGs, Automated Retraining Workflows\n\n### Machine Learning & Deep Learning  \nSupervised, Unsupervised, Reinforcement Learning, Feature Engineering, Model Evaluation, Regularization, Cross-Validation, Transfer Learning, Hyperparameter Optimization  \nFrameworks: scikit-learn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost  \nArchitectures: CNNs, RNNs, Transformers, Autoencoders, Attention Mechanisms  \nExplainability: LIME, SHAP, Grad-CAM, Model Interpretability & Bias Detection\n\n### Generative AI, NLP & LLM Ecosystem  \nLarge Language Models (GPT, LLaMA, Mistral, Claude, Gemini), Prompt Engineering, Prompt Chaining, RAG (Retrieval-Augmented Generation), LoRA/PEFT Fine-Tuning, Context Window Optimization, Embeddings & Semantic Search, Conversational Agents  \nFrameworks: LangChain, LlamaIndex, Haystack, Hugging Face Transformers  \nVector Databases: FAISS, Pinecone, Chroma, Weaviate\n\n### MLOps & Model Lifecycle Management  \nMLflow, Weights & Biases, DVC, Model Registry, Model Validation & Rollback, Automated Retraining, Drift Detection (Evidently AI), Monitoring (Prometheus, Grafana), Experiment Tracking, A/B Testing  \nDeployment & Serving: FastAPI, Flask, gRPC, TensorFlow Serving, TorchServe, BentoML, Streamlit, Gradio  \nVersion Control & CI/CD: Git, GitHub Actions, Jenkins, GitLab CI/CD\n\n### Data Modeling, Warehousing & Storage  \nStar & Snowflake Schema, Dimensional Modeling, Medallion Architecture, Normalization/Denormalization  \nWarehouses: Snowflake, Redshift, BigQuery, Azure Synapse  \nDatabases: PostgreSQL, MySQL, SQL Server, MongoDB, Cassandra, DynamoDB  \nStorage: S3, ADLS, GCS, Delta Tables, Parquet, ORC, Avro\n\n### Feature Engineering & Feature Stores  \nFeast, Tecton, Databricks Feature Store, Real-Time & Batch Feature Pipelines, Data Versioning & Validation for ML, Synthetic Data Generation\n\n### Infrastructure, DevOps & Observability  \nDocker, Kubernetes, Jenkins, Terraform, Helm, CI/CD Pipelines, Infrastructure-as-Code, Monitoring (Prometheus, Grafana), Logging (ELK Stack, OpenTelemetry), Load Balancing, API Gateway, Resource Scaling\n\n### Data Quality, Governance & Security  \nGreat Expectations, Data Validation Frameworks, IAM, RBAC, Audit Logging, Data Lineage, Data Catalogs, Encryption (KMS, SSL/TLS), Compliance (GDPR, HIPAA, SOC2), Metadata Management\n\n### Applied AI Domains  \nComputer Vision (Image Classification, Object Detection, OCR)  \nNatural Language Processing (Text Classification, Summarization, Q&A)  \nTime Series Forecasting, Anomaly Detection, Generative AI (Text-to-Text / Image / Code)\n\n### Visualization, Analytics & Reporting  \nPower BI, Tableau, Looker, Amazon QuickSight, Streamlit, Dash, Plotly, Matplotlib, Seaborn, MLflow UI, W&B Dashboards, Real-Time Monitoring Panels\n\n### Soft Skills & Practices  \nAgile / Scrum, Cross-Functional Collaboration, Technical Documentation, Problem Solving, Model Review & Explainability Sessions, Business Translation of ML Insights\n\n---\n\n##  Output Format\n\nReturn the final skills section in the following format:\n\n• Subheading 1: skill 1, skill 2, skill 3, ..., skill N\n• Subheading 2: skill 1, skill 2, ..., skill N\n...\n• Certifications: AWS Machine Learning Engineer – Associate, Microsoft Power BI Data Analyst (PL-300), Certified Java SE 11 Developer.\n\n\n---\n\n##  Notes\n\n- Make sure the subheadings and skills feel **tailored** to the JD  \n- Don’t exceed **7 subheadings**, and **keep each list focused**  \n- Use **professional resume-ready formatting**, not paragraphs  \n- Only use skills from the provided bank\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3216,
        96
      ],
      "id": "018afe82-44fd-4bc3-9013-d9cf6c503d60",
      "name": "Basic LLM Chain",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=##  Role\nYou are an expert AI assistant for resume optimization, specializing in tailoring skill sections based on a candidate’s master skill bank and the target job description (JD).\n\n---\n\n##  Objective\nGiven:\n1. A comprehensive **base skill bank** (provided below)\n2. A specific **Job Description (JD)**\n\nYour task is to generate a **custom skills section** for the resume that best aligns with the job description.\n\n---\n\n##  Instructions\n\n1. Read the job description thoroughly.\n2. From the provided skill bank, select **at least 80% of the skills** that are **most relevant** to the job role.\n3. Group the selected skills into **5–7 subheadings**, depending on what fits the JD best.\n4. **Each subheading is either a maximum of one word or two words**. Do not exceed that at any circumstance.\n5. **Limit each subheading to a maximum of 6 skills.** Do not exceed this under any condition.\n6. Choose **clear, job-appropriate subheadings** that align with the focus areas of the role (e.g., \"Cloud Platforms\", \"Data Engineering\", etc.).\n7. Use only skills from the skill bank below — **do not invent new ones**.\n8. Include the following **certification section exactly as shown** at the end\n9. The final formatting should strictly follow the output format: all skills in-line, comma-separated, and limited in length.\n\n\n---\n\n##  Input: Job Description\n{{ $json['Summarized Content'] }}\n\n\n---\n\n##  Master Skill Bank\n\n### Programming & Scripting  \nPython, SQL (T-SQL, PL/SQL), Java, Scala, R, Shell Scripting (Bash, PowerShell), JSON, YAML, API Development (REST/gRPC), OOP, Modular Programming, Testing (pytest, unittest)\n\n### Cloud Platforms  \n**Microsoft Azure**: Data Factory, Databricks, Synapse Analytics, Azure Machine Learning, Cognitive Services  \n**AWS**: S3, Glue, Lambda, Redshift, ECS/EKS, SageMaker, Bedrock, Step Functions, EMR  \n**GCP**: BigQuery, Dataflow, Pub/Sub, Vertex AI, AI Platform  \n**Cross-Cloud**: Terraform, CloudFormation, Infrastructure-as-Code (IaC)\n\n### Data Processing, Pipelines & Big Data Frameworks  \nApache Spark (PySpark, Spark SQL), Apache Kafka, Delta Lake, Hadoop (HDFS, MapReduce), Presto, Dask, Lakehouse & Medallion Architecture, Batch & Streaming Data Pipelines, Dataflow, Pub/Sub, Data Lineage & Metadata Management\n\n### ETL / ELT & Workflow Orchestration  \nApache Airflow, dbt, Azure Data Factory, AWS Glue, Apache NiFi, Informatica, Prefect, Kubeflow Pipelines, CI/CD-based pipeline automation, Parameterized DAGs, Automated Retraining Workflows\n\n### Machine Learning & Deep Learning  \nSupervised, Unsupervised, Reinforcement Learning, Feature Engineering, Model Evaluation, Regularization, Cross-Validation, Transfer Learning, Hyperparameter Optimization  \nFrameworks: scikit-learn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost  \nArchitectures: CNNs, RNNs, Transformers, Autoencoders, Attention Mechanisms  \nExplainability: LIME, SHAP, Grad-CAM, Model Interpretability & Bias Detection\n\n### Generative AI, NLP & LLM Ecosystem  \nLarge Language Models (GPT, LLaMA, Mistral, Claude, Gemini), Prompt Engineering, Prompt Chaining, RAG (Retrieval-Augmented Generation), LoRA/PEFT Fine-Tuning, Context Window Optimization, Embeddings & Semantic Search, Conversational Agents  \nFrameworks: LangChain, LlamaIndex, Haystack, Hugging Face Transformers  \nVector Databases: FAISS, Pinecone, Chroma, Weaviate\n\n### MLOps & Model Lifecycle Management  \nMLflow, Weights & Biases, DVC, Model Registry, Model Validation & Rollback, Automated Retraining, Drift Detection (Evidently AI), Monitoring (Prometheus, Grafana), Experiment Tracking, A/B Testing  \nDeployment & Serving: FastAPI, Flask, gRPC, TensorFlow Serving, TorchServe, BentoML, Streamlit, Gradio  \nVersion Control & CI/CD: Git, GitHub Actions, Jenkins, GitLab CI/CD\n\n### Data Modeling, Warehousing & Storage  \nStar & Snowflake Schema, Dimensional Modeling, Medallion Architecture, Normalization/Denormalization  \nWarehouses: Snowflake, Redshift, BigQuery, Azure Synapse  \nDatabases: PostgreSQL, MySQL, SQL Server, MongoDB, Cassandra, DynamoDB  \nStorage: S3, ADLS, GCS, Delta Tables, Parquet, ORC, Avro\n\n### Feature Engineering & Feature Stores  \nFeast, Tecton, Databricks Feature Store, Real-Time & Batch Feature Pipelines, Data Versioning & Validation for ML, Synthetic Data Generation\n\n### Infrastructure, DevOps & Observability  \nDocker, Kubernetes, Jenkins, Terraform, Helm, CI/CD Pipelines, Infrastructure-as-Code, Monitoring (Prometheus, Grafana), Logging (ELK Stack, OpenTelemetry), Load Balancing, API Gateway, Resource Scaling\n\n### Data Quality, Governance & Security  \nGreat Expectations, Data Validation Frameworks, IAM, RBAC, Audit Logging, Data Lineage, Data Catalogs, Encryption (KMS, SSL/TLS), Compliance (GDPR, HIPAA, SOC2), Metadata Management\n\n### Applied AI Domains  \nComputer Vision (Image Classification, Object Detection, OCR)  \nNatural Language Processing (Text Classification, Summarization, Q&A)  \nTime Series Forecasting, Anomaly Detection, Generative AI (Text-to-Text / Image / Code)\n\n### Visualization, Analytics & Reporting  \nPower BI, Tableau, Looker, Amazon QuickSight, Streamlit, Dash, Plotly, Matplotlib, Seaborn, MLflow UI, W&B Dashboards, Real-Time Monitoring Panels\n\n### Soft Skills & Practices  \nAgile / Scrum, Cross-Functional Collaboration, Technical Documentation, Problem Solving, Model Review & Explainability Sessions, Business Translation of ML Insights\n\n---\n\n##  Output Format\n\nReturn the final skills section in the following format:\n\n• Subheading 1: skill 1, skill 2, skill 3, ..., skill N\n• Subheading 2: skill 1, skill 2, ..., skill N\n...\n• Certifications: AWS Machine Learning Engineer – Associate, Microsoft Power BI Data Analyst (PL-300), Certified Java SE 11 Developer.\n\n\n---\n\n##  Notes\n\n- Make sure the subheadings and skills feel **tailored** to the JD  \n- Don’t exceed **7 subheadings**, and **keep each list focused**  \n- Use **professional resume-ready formatting**, not paragraphs  \n- Only use skills from the provided bank\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3232,
        384
      ],
      "id": "74808d28-58c8-49fa-b0bc-49d3bc1d57ec",
      "name": "Basic LLM Chain2",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {
          "frequencyPenalty": 0.1,
          "timeout": 120000,
          "maxRetries": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3392,
        1264
      ],
      "id": "75273a5f-8762-43c8-8a8b-7407ea3ce434",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3376,
        208
      ],
      "id": "d685dea1-281b-4dbe-9bef-ef667bf9ddb3",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {
          "frequencyPenalty": 0.1,
          "timeout": 120000,
          "maxRetries": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3376,
        496
      ],
      "id": "f4b80eda-fe80-4855-9a49-03bc741ee6e3",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## 🧠 Role\nYou are a **resume optimization assistant** specialized in analyzing and refining technical projects for resumes.\n\n## 🎯 Objective\nI will provide you with a list of technical projects. Your tasks are:\n\n1. Carefully **analyze all projects**.\n2. **Select the top 3–4 projects** based on:\n   - Technical depth and innovation\n   - Relevance to the target role: {{ $json['Summarized Content'] }}\n   - Impact and measurable outcomes\n   - Diversity across tools, domains, or problem types\n3. **Rewrite and optimize** the selected projects according to the custom instructions below.\n\n---\n\n## ✍️ Rewrite Instructions\n\nOnce the top projects are selected:\n\n\n- For each project, generate exactly **2 bullet points** that summarize the project clearly.\n- Each bullet point should be **between 80–110 characters** in length.\n- The language should be **HR-friendly** — avoid overly technical jargon, but still include:\n  - Key tools/technologies used (e.g., MLflow, FastAPI, Azure)\n  - Achievements or quantifiable outcomes (e.g., \"15% reduction in RMSE\", \"3x faster queries\")\n- Each project summary should read like a **mini story**:\n  - Make it **immediately understandable** to someone without deep technical background.\n  - Focus on **what the project did** and **what tools/impact** were involved.\n- Avoid overly complex language or breaking the character limits.\n---\n\n## 📄 Input Projects\n\nPaste the following after this section: {{ $json['Projects Section'] }}\n\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3200,
        -752
      ],
      "id": "9f256fd9-0ac2-4bfb-b9b1-e4915e51b7ea",
      "name": "Basic LLM Chain4",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3344,
        -640
      ],
      "id": "d94eafd9-59ff-4803-8db5-b63068b5e5c8",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {
          "frequencyPenalty": 0.1,
          "timeout": 1200000,
          "maxRetries": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3376,
        -384
      ],
      "id": "8cbeedcf-1da5-477e-b981-7c8a6d8379c3",
      "name": "OpenAI Chat Model2",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "content": "## Skills section modification\n",
        "height": 608,
        "width": 864
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2736,
        16
      ],
      "id": "ba2cba4f-fb5d-4cc9-889e-db5804a750cd",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "## Projects modification\n",
        "height": 592,
        "width": 880
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2720,
        -800
      ],
      "id": "b6633018-c3ad-4ab1-ade8-017a90364a8a",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        3824,
        -512
      ],
      "id": "c98bd753-02fa-4535-b74c-c4f12b20bc38",
      "name": "Merge1",
      "alwaysOutputData": false,
      "executeOnce": false,
      "retryOnFail": true
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## 🧠 Role\nYou are a **resume optimization assistant** specialized in analyzing and refining technical projects for resumes.\n\n## 🎯 Objective\nI will provide you with a list of technical projects. Your tasks are:\n\n1. Carefully **analyze all projects**.\n2. **Select the top 3–4 projects** based on:\n   - Technical depth and innovation\n   - Relevance to the target role: {{ $json['Summarized Content'] }}\n   - Impact and measurable outcomes\n   - Diversity across tools, domains, or problem types\n3. **Rewrite and optimize** the selected projects according to the custom instructions below.\n\n---\n\n## ✍️ Rewrite Instructions\n\nOnce the top projects are selected:\n\n\n- For each project, generate exactly **2 bullet points** that summarize the project clearly.\n- Each bullet point should be **between 80–110 characters** in length.\n- The language should be **HR-friendly** — avoid overly technical jargon, but still include:\n  - Key tools/technologies used (e.g., MLflow, FastAPI, Azure)\n  - Achievements or quantifiable outcomes (e.g., \"15% reduction in RMSE\", \"3x faster queries\")\n- Each project summary should read like a **mini story**:\n  - Make it **immediately understandable** to someone without deep technical background.\n  - Focus on **what the project did** and **what tools/impact** were involved.\n- Avoid overly complex language or breaking the character limits.\n---\n\n## 📄 Input Projects\n\nPaste the following after this section: {{ $json['Projects Section'] }}\n\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3200,
        -496
      ],
      "id": "30fe5b89-c1b8-4cc0-91f5-7acd3b0ad9f0",
      "name": "Basic LLM Chain5",
      "retryOnFail": true,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Role\nYou are an expert AI evaluator with a deep understanding of resume writing, hiring criteria, and alignment with job descriptions.\n\n## Task\nYou will evaluate **multiple project summary outputs** generated by different AI models.\n\nYour job is to determine **which output best aligns** with the following **Job Description (JD)** and output that model's response\n\nSo, ultimately what I am looking for is a suitable **tailored project section** \n\n---\n\n## 📄 Input Materials\n\nBoth the model's **project sections**:\n\n1st model: {{ $json.text }}, \n2nd  model: {{ $json['Open AI input'] }}\n\nHere is the **job description** to look for alignment: {{ $('No Operation, do nothing').item.json[\"Summarized Content\"] }}\n\n\n---\n\n\n\n## 🧠 Evaluation Criteria\n\nEvaluate each model output based on the following:\n\n1. **Relevance to the Job Description**\n   - Does the content highlight skills, tools, or experience the JD prioritizes?\n2. **Clarity & Readability**\n   - Is the output easy to understand, HR-friendly, and well-structured?\n3. **Impact Communication**\n   - Are achievements clearly stated with results or quantifiable outcomes?\n4. **Language and Tone**\n   - Does it sound professional, resume-appropriate, and concise?\n\n---\n\n## ✅ Output Format\n\n**Your entire output MUST be a single JSON object. **DO NOT include any additional text or markdown outside of the JSON block.**\n\n{\n  \"best_project_content\": \"[Insert the complete projects content from the winning model here]\"\n}\n\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4096,
        -512
      ],
      "id": "6a0dc193-5fd8-4c4b-87e2-136abea21a85",
      "name": "Basic LLM Chain6",
      "alwaysOutputData": false,
      "retryOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {
          "timeout": 100000,
          "maxRetries": 2
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4240,
        -400
      ],
      "id": "9da3f26e-0767-4944-b924-f18b81f1cc73",
      "name": "OpenAI Chat Model3",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        3904,
        256
      ],
      "id": "36aa1f20-a015-4031-967d-8b020c86d074",
      "name": "Merge2"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Role\nYou are a resume evaluation assistant with expertise in job description analysis, skill relevance, and formatting clarity.\n\n---\n\n## Objective\nCompare multiple **AI-generated resume skill sections** and select the best one that aligns with the provided **Job Description (JD)**.\n\n## Most important rules to remember when combining skills\n\n1. **Do not create any new skills**\n2. The total **number of subheadings should not exceed 7**.\n3. The total **number of skills under each subheading should not exceed 6**.\n\n---\n\n## 📥 Inputs\n\n### 🧾 Job Description\n\n{{ $('No Operation, do nothing').item.json[\"Summarized Content\"] }}\n\n---\n\n### 📦 Skill Sections from Different Models\n\n\n1st model: {{ $json.text }}\n2nd model: {{ $json['Open AI input'] }}\n\n\n\n##  Evaluation Criteria\n\nCompare each model's output using the following criteria:\n\n1. **Relevance to the JD**\n   - Are the skills chosen closely aligned with the responsibilities and tools in the job?\n2. **Coverage from Base Skill Bank**\n   - Is at least 80% of the content traceable to the provided master skill bank?\n3. **Subheading Quality**\n   - Are subheadings meaningful and grouped logically (5–7 total)?\n4. **Skill Limit Enforcement**\n   - Does each subheading stay within the 6-skill maximum?\n5. **Formatting**\n   - Are all sections clearly formatted, comma-separated, and resume-ready?\n6. **Certifications**\n   - Is the certifications section present and correctly formatted?\n\n\n## Output Format\n\nReturn your evaluation as follows:\n\n- Final Combined Output:\n  • Subheading 1: skill 1, skill 2, ..., skill N\n  • Subheading 2: skill 1, skill 2, ..., skill N\n  ...\n  • Certifications: AWS Machine Learning Engineer – Associate, Microsoft Power BI Data Analyst (PL-300), Certified Java SE 11 Developer\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4144,
        256
      ],
      "id": "99d94da6-e0eb-465c-92af-a6117066ee13",
      "name": "Basic LLM Chain7",
      "retryOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {
          "timeout": 120000,
          "maxRetries": 2
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4288,
        368
      ],
      "id": "a0e33e69-7441-4b4c-9149-cccedff22c9d",
      "name": "OpenAI Chat Model4",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "reset": false
        }
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        352,
        48
      ],
      "id": "3375d6dd-eed2-48ec-8a2b-8e2ba83704f3",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "amount": 10
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        832,
        176
      ],
      "id": "7ca6a663-df7e-4028-af25-35ac8d592143",
      "name": "Wait",
      "webhookId": "3c228277-5c70-431b-84c9-d0c2d0645ab7"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        3936,
        1040
      ],
      "id": "c4a3274c-c909-444e-accf-25e6e61afa5f",
      "name": "Merge3"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=##  Role\nYou are a resume evaluation AI assistant. You will review experience sections from multiple LLMs and produce the best possible version  by selecting the best single output.\n\n---\n\n##  Objective\nYour task is to evaluate the following experience sections (created using the same base content and job description) and return a single, final version that is:\n\n- Tailored accurately to the JD\n- Well-formatted, resume-ready, and quantifiable\n- Uses bullet points with 100–120 characters each\n- Clearly communicates accomplishments and responsibilities\n\n---\n\n## 🧾 Job Description\n\n{{ $('No Operation, do nothing').item.json['Summarized Content'] }}\n\n\n---\n\n## 📄 LLM Inputs\n\n1st model input: {{ $json.text }}\n2nd model input: {{ $json['Open AI input'] }}\n\n\n##  Output Instructions\n\n- Do **not** explain your choice\n- Do **not** give a ranking or reasoning\n- Simply return the **final optimized experience section** in the exact format below\n\n---\n\n## 🧾 Output Format\n\n\n- Return the **entire final experience section** in this format:\n\n  [Job Title] | [Dates] | [Company], [Location]\n  Bullet 1 (100–120 characters)\n  Bullet 2 (100–120 characters)\n  Bullet 3 (100–120 characters)\n  Bullet 4 (if needed, 100–120 characters)",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4176,
        1040
      ],
      "id": "13d9d3b2-203d-4a93-aa6a-8218d6a728e1",
      "name": "Basic LLM Chain8",
      "retryOnFail": true,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5",
          "mode": "list",
          "cachedResultName": "gpt-5"
        },
        "options": {
          "timeout": 150000,
          "maxRetries": 3
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4304,
        1152
      ],
      "id": "9da765f6-c3c6-4226-8a6a-9140512111f5",
      "name": "OpenAI Chat Model5",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "33b3911d-e0a5-4d1d-abf4-a2fb61f9f32c",
              "name": "Open AI input",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3616,
        -496
      ],
      "id": "fd6f398d-8f13-456b-bdc3-a7470a122d01",
      "name": "Edit Fields2"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "aff78c3b-510c-4e48-9a1d-a7602eabca59",
              "name": "Open AI input",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3616,
        384
      ],
      "id": "bf5c2fcd-7c12-41b0-a214-8a9d41e854fc",
      "name": "Edit Fields3"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "41886fc5-25ba-47dc-b86a-3910a5028bbf",
              "name": "Open AI input",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3616,
        1152
      ],
      "id": "f8136b6a-c2a9-4e03-acf6-d0f304d0c304",
      "name": "Edit Fields4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Role\nYou are a LaTeX formatting assistant specialized in transforming project descriptions into a standardized LaTeX resume format.  \n\n---\n\n## Objective\nYou will receive an unorganized or plain-text **Projects section**.  \nYour task is to:\n- **Convert** it into the specified LaTeX format below  \n- **Do not add, remove, or rewrite** any content  \n- Preserve the original meaning, wording, and metrics exactly as given  \n- Only structure it using correct LaTeX syntax  \n\n---\n\n##  Formatting Rules\n\nEach project should follow this exact structure:\n\n\\noindent \\textbf{[Project Name]}, \\textit{[Keywords · limited to 4 items]}\n\\begin{itemize}[noitemsep, topsep=2pt, leftmargin=2em]\n\\item [Bullet point 1 — original text, properly escaped for LaTeX (e.g., Q&A, %, _)]\n\\item [Bullet point 2 — original text, properly escaped for LaTeX (e.g., Q&A, %, _)]\n\\item [Bullet point 3 — original text, properly escaped for LaTeX (e.g., Q&A, %, _)](if present)\n\\end{itemize}\n\n\n### Notes:\n- Escape all LaTeX-sensitive characters properly:\n  - `%` → `\\%`\n  - `&` → `\\&`\n  - `_` → `\\_`\n- Use **only up to 4 keywords** separated by `·` (middle dots).  \n  Example: `GenAI · LangChain · RAG · FastAPI`\n- Preserve **original punctuation, capitalization, and metrics** (e.g., 20%, RMSE, etc.).\n- Maintain the **spacing and indentation** shown in the example.\n\n---\n\n## Input \n\nYou will receive input like this:\n{{ $json.text }}\n\n---\n\n## Output Format\n\nReturn only the LaTeX-formatted project section in the exact style below and as explained in the formatting rules. Nothing else. \n\n\\noindent \\textbf{Project Name}, \\textit{Keyword1 · Keyword2 · Keyword3 · Keyword4}\n\\begin{itemize}[noitemsep, topsep=2pt, leftmargin=2em]\n\\item Bullet 1 (escaped)\n\\item Bullet 2 (escaped)\n\\end{itemize}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4528,
        -528
      ],
      "id": "62f59bb0-6da8-415d-a28e-db263845e2d7",
      "name": "Basic LLM Chain9",
      "retryOnFail": true
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5-mini",
          "mode": "list",
          "cachedResultName": "gpt-5-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4656,
        -416
      ],
      "id": "99167943-e391-4a9e-9000-3029e48cde5f",
      "name": "OpenAI Chat Model6",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=##  Role\nYou are a LaTeX formatting assistant that specializes in transforming resume skill sections into structured LaTeX code.\n\n---\n\n##  Objective\nYou will be provided with a raw or loosely structured **skills section**. Your job is to:\n- **Reorganize and format** the input into the given LaTeX structure\n- **Do not modify, rewrite, or omit** any content\n- Use LaTeX syntax and formatting exactly as shown in the template\n\n---\n\n##  Formatting Rules\n\nUse this LaTeX template for output:\n\n% Skills and Certifications\n\\section*{SKILLS AND CERTIFICATIONS}\n\\hrule\n\\vspace{0.1cm}\n\\begin{itemize}[noitemsep, topsep=0em, leftmargin=2em]\n\\item \\textbf{[Subheading 1:]} skill 1, skill 2, skill 3, ...\n\\item \\textbf{[Subheading 2:]} skill 1, skill 2, ...\n...\n\\item \\textbf{Certifications:} Certification 1, Certification 2, Certification 3\n\\end{itemize}\n\n\n### ⚙️ Notes:\n- Each skill category must start with `\\item \\textbf{Category:}` followed by comma-separated skills\n- Escape LaTeX-sensitive characters (e.g., `%` → `\\%`, `_` → `\\_`)\n- Preserve **capitalization**, **abbreviations**, and **groupings** from the input\n- Always include a final `Certifications:` line with all relevant certifications, if already present, do nothing.\n\n---\n\n##  Input\n\nYou will receive input like this:\n{{ $json.text }}\n\n\n---\n\n##  Output Format\n\nReturn **only the LaTeX-formatted code** like mentioned in the formatting rules. \n\n\n---\n\n Your job is to **only convert** the input into valid LaTeX using this format. **Do not rewrite** or elaborate on any skill content.\n\n\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4592,
        240
      ],
      "id": "413bdc8b-d91b-44b4-bcb6-bcb7498336a6",
      "name": "Basic LLM Chain10",
      "retryOnFail": true
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-5-mini",
          "mode": "list",
          "cachedResultName": "gpt-5-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4736,
        352
      ],
      "id": "77806fb9-9324-4b6e-b1de-1a7751a37b5d",
      "name": "OpenAI Chat Model7",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=##  Role\nYou are a LaTeX formatting assistant that specializes in structuring professional experience sections for resumes in LaTeX format.\n\n---\n\n##  Objective\nYou will receive a set of raw or unformatted **work experience entries**. Your task is to:\n- **Format each experience entry** into the LaTeX style provided below\n- Use the original content exactly — **do not modify, paraphrase, or remove any points**\n- Apply proper LaTeX escaping and formatting conventions\n\n---\n\n##  LaTeX Template to Follow\n\nUse the following structure for **each experience**:\n\n\\noindent\\textbf{[Company or Organization]} \\hfill {[Location]} \\\\\\\\\n\\textit{[Job Title]} \\hfill \\textit{[Start Date – End Date]}\n\\begin{itemize}[noitemsep, topsep=2pt, leftmargin=2em]\n\\item [Bullet point 1 — properly escaped for LaTeX]\n\\item [Bullet point 2 - properly escaped for LaTeX]\n\\item [Bullet point 3 - properly escaped for LaTeX]\n\\item [Bullet point 4 - properly escaped for LaTeX](if present)\n\\end{itemize}\n\n\n\n---\n\n##  Formatting Rules\n\n- **Company/Org Name** → in `\\textbf{}`  \n- **Location** → in `\\hfill {City, State}`\n- **Job Title** → in `\\textit{}`  \n- **Dates** → in `\\textit{Start – End}` (month abbreviation optional)\n- **Escape LaTeX characters** properly:\n  - `%` → `\\%`\n  - `&` → `\\&`\n  - `_` → `\\_`\n- Format tools, platforms, and technologies inside bullet points using `\\textbf{}` only if they are **product/tool names** (e.g., `\\textbf{Azure Data Factory}`, `\\textbf{PySpark}`, `\\textbf{SQL}`)\n\n---\n\n##  Input Format\n\nYou will receive input like this:\n{{ $json.text }}\n\n\n---\n\n##  Output Format\n\nReturn the output in the **LaTeX format explained in latex template to follow** (no explanations, just the code)\n\n\n---\n\nReturn the above format for **every experience entry you receive**. If there are multiple experiences, stack them one after the other.\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        4624,
        1024
      ],
      "id": "3eae9cd1-9989-4f07-8032-11fe6185687c",
      "name": "Basic LLM Chain11",
      "retryOnFail": true
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "ed3ca7ce-9c8e-45e0-b6dd-9a30676dcc18",
              "name": "Skills",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4976,
        240
      ],
      "id": "627f4436-4c1f-46c0-8301-d93170a9c0e1",
      "name": "Edit Fields5"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "231228ba-1973-4135-8156-8a68956970a6",
              "name": "projects",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4912,
        -528
      ],
      "id": "0628969d-5cf6-4b87-ac7e-b9d133e58496",
      "name": "Edit Fields6"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "fddea055-efef-4097-b09c-03a991f64116",
              "name": "Experience",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4976,
        1024
      ],
      "id": "bd4de205-1cd4-4b43-98f2-d43e4fdc85ef",
      "name": "Edit Fields7"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 4,
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        5616,
        416
      ],
      "id": "a37109c9-fdc0-46e7-b669-13abe1f21c70",
      "name": "Merge4"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4752,
        1136
      ],
      "id": "01d8b614-2599-40f6-aa22-5e0fefeea098",
      "name": "Google Gemini Chat Model3",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "value": "1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE",
          "mode": "list",
          "cachedResultName": "test-joblist",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit?usp=drivesdk"
        },
        "sheetName": {
          "__rl": true,
          "value": 208966211,
          "mode": "list",
          "cachedResultName": "final-job-list",
          "cachedResultUrl": "https://docs.google.com/spreadsheets/d/1v7K3bqe_XJxSPexyUE2oHUFZmQDPJNYnM-3Uk777cKE/edit#gid=208966211"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "All the jobs listed here": "=\\documentclass[a4paper,11pt]{article}\n\\usepackage{geometry}\n\\geometry{left=0.30in, right=0.30in, top=0.40in, bottom=0.40in}\n\\usepackage{enumitem}\n\\usepackage{titlesec}\n\\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue]{hyperref}\n\\usepackage{xcolor}\n\\usepackage{fontawesome5} % For icons\n\\usepackage{mathptmx}\n\n\n\\usepackage{setspace} % Optional for advanced spacing control\n\n% Define color for hyperlinks\n\\hypersetup{\n    colorlinks=true,\n    urlcolor=black,\n}\n\n% Reduce vertical spacing between sections\n\\titlespacing{\\section}{0pt}{2pt}{2pt}\n\\titlespacing{\\subsection}{0pt}{1pt}{1pt}\n\n% Formatting for side headings\n\\titleformat{\\section}{\\large\\bfseries}{}{0pt}{}\n\\titleformat{\\subsection}{\\normalsize\\bfseries}{}{0pt}{}\n\n\\begin{document}\n\n\\begin{center}\n    \\textbf{\\LARGE Ashish Gupta Konagalla} \\\\\\\\[0cm]\n    \\textbf{Data Engineer \\textbar\\ ETL/ELT Pipelines · LLM/ML Data · Distributed Systems · Compliance (HIPAA/FHIR)} \\\\\\\\[0.1cm]\n\n    \\href{mailto:konagalla.ashishg@gmail.com}{\\faEnvelope \\ konagalla.ashishg@gmail.com} \\hspace{1cm}\n    \\href{tel:+14103365795}{\\faPhone \\ +1 (410) 336-5795} \\hspace{1cm}\n    \\href{https://linkedin.com/in/ashish-gupta-konagalla}{\\faLinkedin \\ Linkedin} \\hspace{0.5cm} \n    \\href{https://github.com/ashishkonagalla}{\\faGithub \\ Github} \\hspace{1cm}\n    \\textcolor{black}{\\faHome \\ Boston, MA}\n\\end{center}\n\n\n\n\\vspace{-0.9em}\n\n\\setlength{\\parskip}{0pt} % Removes extra space between paragraphs\n\\setlength{\\lineskip}{0pt} % Removes additional line spacing\n\\setlength{\\baselineskip}{0.9\\baselineskip}\n\n{{ $json.text }}\n\n\\section*{WORK EXPERIENCE}\n\\hrule\n\\vspace{0.1cm}\n{{ $('Merge4').item.json.Experience }}\n\n\n{{ $('Merge4').item.json.Skills }}\n\n% Education Section\n\\setlength{\\parskip}{0pt} % Removes extra space between paragraphs\n\\setlength{\\lineskip}{0pt} % Removes additional line spacing\n\\setlength{\\baselineskip}{0.8\\baselineskip}\n % Sets line spacing to the minimal default\n\n\n\\section*{EDUCATION}\n\\hrule\n\\vspace{0.1cm}\n\\noindent\\textbf{\\textsc{University of Maryland, Baltimore County (UMBC)}} \\hfill \\textit{Baltimore, MD}\\\\\\\\\n\\noindent\\textit{Master of Science, Computer Science (GPA: 3.70/4.00)}\\hfill\\textit{Aug 2023 – May 2025}\\\\\\\\\n\\noindent\\textit{Bachelor of Science, Computer Science (GPA: 3.41/4.00)}\\hfill\\textit{Aug 2018 – May 2022}\\\\\\\\\n\\noindent\\textbf{\\small Coursework}: {\\small \\textit{Data Science, Database Management, Algorithms, Machine Learning, Artificial Intelligence, Statistical Analysis}}\n\n\n% Adjust the spacing parameters for better readability\n\\setlength{\\parskip}{0pt} % No extra space between paragraphs\n\\setlength{\\itemsep}{1pt} % Space between bullet points in itemize\n\\setlength{\\parindent}{0pt} % No paragraph indentation\n\\setlength{\\baselineskip}{1.1\\baselineskip} % Slightly increase line spacing\n\n\n\n\n\\section*{\\makebox[0pt][l]{PROJECTS\\hspace{1em}\n\\href{https://github.com/ashishkonagalla?tab=repositories}\n{\\colorbox{gray!0}{\\faGithub~\\textcolor{blue}{Github}}}}}\n\\hrule \n\\vspace{0.1cm}\n{{ $('Merge4').item.json.projects }}"
          },
          "matchingColumns": [
            "All the jobs listed here"
          ],
          "schema": [
            {
              "id": "All the jobs listed here",
              "displayName": "All the jobs listed here",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "type": "string",
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.7,
      "position": [
        6704,
        448
      ],
      "id": "48de78fd-ccbb-4808-b8fa-9d32421675db",
      "name": "Append row in sheet1",
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "UpzjIFdaCBQqTUWW",
          "name": "Google Sheets account 2"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## 🧠 Role\nYou are a professional resume assistant trained to write high-impact, ATS-optimized professional summaries and job titles for technical resumes.\n\n---\n\n## 🎯 Objective\nYour task is to generate\n\n1. A **resume summary** that is:\n    - Aligned with a specific **Job Description (JD)**\n    - Based on provided **Experience**, **Skills**, and **Projects**\n    - **Strictly between 425 and 475 characters** (including spaces)\n    - Written in a **professional, confident, and recruiter-friendly tone**\n    - Focused on **3 core strengths or differentiators** that best align with the JD\n\n2. A **resume title** (headline) that is:\n   - Clear, relevant, and keyword-rich\n   - Max **70 characters**\n   - Reflective of the candidate’s capabilities and the JD\n   - Written in this format:\n     ```\n     Job Title | Keyword · Keyword · Keyword · Keyword\n     ```\n\n---\n\n## ✅ Formatting & Language Rules\n\nFor the **summary**:\n    - Do **not** rewrite or invent new experiences\n    - Use existing information from the experience, skills, and projects sections\n    - Mention **3 key strengths** (e.g., LLM apps, scalable systems, cloud deployment) that match the JD\n    - Summary must be **natural and well-flowing**, not just a list of keywords\n    - Maintain a balance of:\n      - **Technical skills/tools**\n      - **Business/impact language**\n      - **Certifications/credentials** (optional, if space allows)\n    - Tone should be **confident, concise**, and **tailored to the role type** (e.g., Full Stack, AI, Data)\n\nFor the **resume title**:\n- Keep it **within 70 characters**\n- Include 1 job role and 3–4 concise, high-impact keywords from the JD\n- Use middle dots (`·`) to separate keyword phrases\n- Make it ATS-friendly and relevant to the role type (e.g., AI, Data, Full Stack)\n\n---\n\n## 📥 Inputs You Will Receive\n\n- **Job Description:** {{ $node['No Operation, do nothing'].json[\"Summarized Content\"] }}\n- **Experience Section:** {{ $json.Experience }} , **Projects Section:** {{ $json.projects }}, and **Skills Section:** {{ $json.Skills }}\n\n---\n\n## 📤 Output Format\n\nReturn the **final resume summary with specified example latex format** and the generated resume titles specified with the example latex format. with no commentary, explanations, or extra text.\n\nExample structure for summary:\n\n\\section*{SUMMARY}\n\\hrule\n\\vspace{0.1cm}\n\\noindent AI Engineer with 3+ yrs experience building LLM apps, scalable pipelines & real-time cloud systems. Delivered RAG-based legal assistant, automated ML workflows with Airflow & deployed APIs via FastAPI/Docker. Skilled in Python, Azure, MLflow. MS in CS (GPA 3.9), AWS ML certified.\n\nExample structure for resume titles:\n   ```\n   Job Title | Keyword · Keyword · Keyword · Keyword\n   ```\n\n---\n\n✅ Final output must:\nFor summary:\n- Be **425–475 characters** long (including spaces)\n- Be written in **one paragraph**\n- Highlight **3 JD-relevant strengths**\nFor resume titles:\n- Be only 4 keywords maximum starting with the job title.",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        6144,
        448
      ],
      "id": "4dba2d7a-6421-45df-9b74-75e6f9f2a510",
      "name": "Basic LLM Chain12",
      "retryOnFail": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        6288,
        560
      ],
      "id": "3a9e2514-dae6-459e-8487-1ecdf9467f71",
      "name": "Google Gemini Chat Model4",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4016,
        -384
      ],
      "id": "909dc743-c706-4570-bed4-3a3870fd6402",
      "name": "Google Gemini Chat Model5",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3168,
        -624
      ],
      "id": "9bfd0cff-8613-406a-ad5b-805793c3436c",
      "name": "OpenAI Chat Model8",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3216,
        -368
      ],
      "id": "39251d08-8770-4cd9-9b08-39108573faa1",
      "name": "Google Gemini Chat Model6",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4496,
        -400
      ],
      "id": "929d3d89-fd16-4c86-bdc8-3d9a86bf1782",
      "name": "Google Gemini Chat Model7",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3216,
        224
      ],
      "id": "d7661b5c-1995-45d0-8ec5-e07fb60e6390",
      "name": "OpenAI Chat Model9",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3216,
        496
      ],
      "id": "64f52165-0e73-4a30-b068-f7a87112e5b4",
      "name": "Google Gemini Chat Model8",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4096,
        368
      ],
      "id": "3d532e4b-3113-4898-9af9-c5a387cf477f",
      "name": "Google Gemini Chat Model9",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-flash-lite",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4544,
        352
      ],
      "id": "3af33076-20b4-4a3b-9d23-755359d360e1",
      "name": "Google Gemini Chat Model10",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        3184,
        992
      ],
      "id": "9697c3ee-f075-40e6-8789-23551397b2dd",
      "name": "OpenAI Chat Model10",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3168,
        1264
      ],
      "id": "8ff1e33a-5dbd-4072-91cf-1b1dd6c07987",
      "name": "Google Gemini Chat Model11",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        4096,
        1152
      ],
      "id": "f1929037-57b9-4f70-89e5-9828fcca19b8",
      "name": "Google Gemini Chat Model12",
      "credentials": {
        "googlePalmApi": {
          "id": "4zZChnfHcxDZuGEx",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1-mini",
          "mode": "list",
          "cachedResultName": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        4576,
        1152
      ],
      "id": "830dc490-7900-4635-9c65-197fd84f08f2",
      "name": "OpenAI Chat Model11",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4.1-mini"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        6064,
        560
      ],
      "id": "cc447c6e-4a73-47bb-94f2-01d4ae741a09",
      "name": "OpenAI Chat Model12",
      "credentials": {
        "openAiApi": {
          "id": "LDDseopU8psJlKRn",
          "name": "OpenAi account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "Google Sheets Trigger": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          },
          {
            "node": "Code in JavaScript2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code in JavaScript1": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [],
        [],
        [
          {
            "node": "Code in JavaScript",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code in JavaScript": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Scrape a url and get its content": {
      "main": [
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Message a model": {
      "main": [
        [
          {
            "node": "Append row in sheet",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Append row in sheet": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields1": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code in JavaScript2": {
      "main": [
        [
          {
            "node": "Code in JavaScript1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "No Operation, do nothing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "No Operation, do nothing": {
      "main": [
        [
          {
            "node": "Basic LLM Chain4",
            "type": "main",
            "index": 0
          },
          {
            "node": "Basic LLM Chain5",
            "type": "main",
            "index": 0
          },
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          },
          {
            "node": "Basic LLM Chain2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Basic LLM Chain1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Basic LLM Chain3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Message a model",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain3",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain4",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain5",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain4": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain5": {
      "main": [
        [
          {
            "node": "Edit Fields2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Basic LLM Chain6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain6",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain2": {
      "main": [
        [
          {
            "node": "Edit Fields3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Basic LLM Chain7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain7",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Scrape a url and get its content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain1": {
      "main": [
        [
          {
            "node": "Merge3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain3": {
      "main": [
        [
          {
            "node": "Edit Fields4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge3": {
      "main": [
        [
          {
            "node": "Basic LLM Chain8",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain8",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields2": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields4": {
      "main": [
        [
          {
            "node": "Merge3",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields3": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Basic LLM Chain6": {
      "main": [
        [
          {
            "node": "Basic LLM Chain9",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "OpenAI Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain9",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain7": {
      "main": [
        [
          {
            "node": "Basic LLM Chain10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain10",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain8": {
      "main": [
        [
          {
            "node": "Basic LLM Chain11",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain9": {
      "main": [
        [
          {
            "node": "Edit Fields6",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain10": {
      "main": [
        [
          {
            "node": "Edit Fields5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain11": {
      "main": [
        [
          {
            "node": "Edit Fields7",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields5": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields6": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields7": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Google Gemini Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain11",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Merge4": {
      "main": [
        [
          {
            "node": "Basic LLM Chain12",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain12",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain12": {
      "main": [
        [
          {
            "node": "Append row in sheet1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain6",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain4",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain5",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain9",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Chat Model9": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model9": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain7",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model10": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain10",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Chat Model10": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model11": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain3",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model12": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain8",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Chat Model11": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain11",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Chat Model12": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain12",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "ZJTgNUDk6VNCwYw2"
  },
  "versionId": "37364122-ee6b-4862-8320-fcef93d75e1d",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "23a605645bd925ae9d0b8e717af47d9eac4271495a6518dbbd8451e6de5eca8f"
  },
  "id": "ZJTgNUDk6VNCwYw2",
  "tags": []
}